{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e071822",
   "metadata": {},
   "source": [
    "### Read the results csv\n",
    "\n",
    "Analyse what we got from the evaluation of the locators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e6613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def extract_files_for_project(project_name, target_dir):\n",
    "    lg_file,num_located,skipped,locators=None,None,None,None\n",
    "    for file_name in os.listdir(target_dir):\n",
    "        if file_name.startswith(\"locators_generation\") and file_name.endswith(f\"{project_name}.csv\"):\n",
    "            lg_file=file_name\n",
    "        elif file_name.endswith(f\"{project_name}_located.csv\"):\n",
    "            num_located=file_name\n",
    "        elif file_name.endswith(f\"{project_name}_skipped.csv\"):\n",
    "            skipped=file_name\n",
    "        elif file_name.endswith(f\"{project_name}.csv\"):\n",
    "            locators=file_name\n",
    "    return lg_file,num_located,skipped,locators\n",
    "\n",
    "root_dir=\"C:\\\\Users\\\\hilal.taha\\\\PycharmProjects\\\\pythonProject\\\\database\\\\statistics\\\\\"\n",
    "lg_files,num_locateds,skippeds,locatorss=[],[],[],[]\n",
    "for model in os.listdir(root_dir+\"trained_models\"):\n",
    "    project_name = model[:len(model) - 14]\n",
    "    lg_file, num_located, skipped, locators = extract_files_for_project(project_name, root_dir+\"evaluation_data\\\\\")\n",
    "    if lg_file is None or num_located is None or skipped is None or locators is None:\n",
    "        continue\n",
    "    lg_files.append(lg_file)\n",
    "    num_locateds.append(num_located)\n",
    "    skippeds.append(skipped)\n",
    "    locatorss.append(locators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f793122",
   "metadata": {},
   "source": [
    "## Calculate the accuracies and robustness\n",
    "\n",
    "We loop per row, calculate the accuracy(recoil) on each row, seperating the SEL and RELOC locators\n",
    "Then at the end of the rows, we divide on the number of rows to get the average accuracy.\n",
    "\n",
    "### Robustness \n",
    "It is the duration of survival of the locator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ecb9bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for -: 'str' and 'int'\n",
      "unsupported operand type(s) for -: 'str' and 'int'\n",
      "unsupported operand type(s) for -: 'str' and 'int'\n",
      "unsupported operand type(s) for -: 'str' and 'int'\n",
      "unsupported operand type(s) for -: 'str' and 'int'\n",
      "unsupported operand type(s) for -: 'str' and 'int'\n",
      "unsupported operand type(s) for -: 'str' and 'int'\n",
      "unsupported operand type(s) for -: 'str' and 'int'\n",
      "unsupported operand type(s) for -: 'str' and 'int'\n",
      "unsupported operand type(s) for -: 'str' and 'int'\n",
      "[0.9838709677419355, 0.952755905511811, 1.0, 0.0, 0.975, 0.9890710382513661, 0.9543147208121827, 0.9797979797979798, 0.9425287356321839, 0.9041796528948216, 1.0, 1.0, 0.9948979591836735, 0.0, 0.995, 0.7738693467336684, 1.0, 0.9646153846153845, 0.9424083769633508, 0.34615384615384615, 0.9650822510822514, 1.0, 0.8943384757025996, 0.12610858529225877, 0.8059049079754599, 0.075, 0.9181818181818184, 1.0, 0.9949494949494949, 0.85, 0.93, 1.0, 1.0, 1.0, 0.12610858529225877, 0.9973333333333333, 0.6088174506652773, 0.922619047619048, 0.9767441860465116, 0.95, 0.9333333333333333, 0.9888731060606061, 0.949748743718593, 1.0, 0.88, 1.0, 1.0, 0.9839705882352938, 1.0, 1.0, 0.9447236180904522, 0.9936708860759493, 1.0, 1.0, 0.335, 0.7878787878787878, 1.0, 0.927166666666665, 0.0, 0.9487179487179487, 0.9666666666666668, 1.0, 0.995, 1.0, 0.8009259259259259, 0.9685574229691876, 0.4628172588832484, 0.995, 0.9767441860465116, 1.0, 1.0, 0.40714285714285714, 1.0, 1.0, 1.0, 0.995, 0.23387096774193547, 0.23387096774193547, 1.0, 1.0, 0.949748743718593, 0.9689689098780008, 0.0, 1.0, 0.9756309523809488, 1.0, 0.91, 0.0, 1.0, 0.975, 0.885, 0.995, 0.7252326217843459, 0.9830438861069956, 0.96, 0.96, 0.39, 0.39, 1.0, 0.9316519607843132, 0.985, 0.0, 1.0, 1.0, 1.0, 0.95, 0.99, 0.4789473684210526, 0.4789473684210526, 1.0, 1.0, 1.0, 0.7777777777777778, 0.9795918367346939, 0.995, 1.0, 1.0, 1.0, 1.0, 0.7441860465116279, 0.135, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def calculate_duration_of_survival(col,dos=1,):\n",
    "    survival_duration = 0\n",
    "    consecutive_zeros = 0\n",
    "    for value in col[::-1]:\n",
    "        if value == 0:\n",
    "            consecutive_zeros += 1\n",
    "            if consecutive_zeros == dos:\n",
    "                break\n",
    "        else:\n",
    "            survival_duration += 1\n",
    "            consecutive_zeros = 0\n",
    "    return survival_duration\n",
    "\n",
    "def calculate_locator_length(col):\n",
    "    locator_name = col.name  # Get the column name (locator name)\n",
    "    locator_parts = re.split('/', locator_name.replace('//','/'))  # Split on '/ ' and '//'\n",
    "    locator_length = len(locator_parts)\n",
    "    if locator_name[-6:]==\"_RELOC\" or locator_name[:5]==\"xpath\":\n",
    "        locator_length=locator_length-1\n",
    "    return locator_length\n",
    "\n",
    "def calculate_accuracy(col):\n",
    "    TP=0\n",
    "    FP=0\n",
    "    for value in col[::-1]:\n",
    "        if value > 0:\n",
    "            TP+=1\n",
    "            FP+=value-1\n",
    "    if TP+FP==0:\n",
    "        return 0\n",
    "    return TP/(TP+FP)\n",
    "\n",
    "def replace_greater_than_one(x):\n",
    "    return 1 if x > 1 else x\n",
    "\n",
    "def compute_reloc_recoil(row):\n",
    "    row_series = pd.Series(row)\n",
    "    positives_count = (row_series[reloc_columns] > 0).sum()\n",
    "    zero_count = len(row_series[reloc_columns]) - positives_count\n",
    "    tp_count = positives_count\n",
    "    fp_count =  row_series[reloc_columns].sum() - positives_count\n",
    "    if tp_count + fp_count == 0:\n",
    "        selected_ratio = 0  # Avoid division by zero\n",
    "    else:\n",
    "        selected_ratio = tp_count / (tp_count + fp_count)\n",
    "    \n",
    "    return selected_ratio\n",
    "\n",
    "\n",
    "def compute_sel_recoil(row):\n",
    "    row_series = pd.Series(row)\n",
    "    \n",
    "    positives_count = (row_series[sel_columns] > 0).sum()\n",
    "    zero_count = len(row_series[sel_columns]) - positives_count\n",
    "    tp_count = positives_count\n",
    "    fp_count =  row_series[sel_columns].sum() - positives_count\n",
    "    \n",
    "    \n",
    "    if tp_count + fp_count == 0:\n",
    "        selected_ratio = 0  # Avoid division by zero\n",
    "    else:\n",
    "        selected_ratio = tp_count / (tp_count + fp_count)\n",
    "    \n",
    "    return selected_ratio\n",
    "\n",
    "reloc_columns = None\n",
    "sel_columns=[]\n",
    "xpath_sel_columns = None\n",
    "class_sel_columns = None\n",
    "name_sel_columns = None\n",
    "id_sel_columns = None\n",
    "tag_sel_columns = None\n",
    "link_sel_columns = None\n",
    "all_columns = None\n",
    "accuracies_RELOC=[]\n",
    "accuracies_SEL=[]\n",
    "dos_sel=[]\n",
    "dos_RELOC=[]\n",
    "df_d=None\n",
    "\n",
    "for file in num_locateds:\n",
    "    # Read the CSV file\n",
    "#     print(file)\n",
    "    try:\n",
    "        df = pd.read_csv(root_dir+\"evaluation_data\\\\\"+file, index_col=\"Timestamp\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    # Step 2: Calculate the duration of survival for each locator\n",
    "    reloc_columns = df.columns[df.columns.str.endswith(\"_RELOC\")]\n",
    "#     sel_columns = df.columns[df.columns.str.endswith(\"_SEL\")]\n",
    "    xpath_sel_columns = df.columns[df.columns.str.startswith(\"xpath\") & df.columns.str.endswith(\"_SEL\")]\n",
    "    class_sel_columns = df.columns[df.columns.str.endswith(\"_SEL\") & df.columns.str.startswith(\"class name\")]\n",
    "    name_sel_columns = df.columns[df.columns.str.endswith(\"_SEL\") & df.columns.str.startswith(\"name\")]\n",
    "    id_sel_columns = df.columns[df.columns.str.endswith(\"_SEL\") & df.columns.str.startswith(\"id\")]\n",
    "    tag_sel_columns = df.columns[df.columns.str.endswith(\"_SEL\") & df.columns.str.startswith(\"tag name\")]\n",
    "    link_sel_columns = df.columns[df.columns.str.endswith(\"_SEL\") & df.columns.str.startswith(\"link text\")]\n",
    "    all_columns = df.columns[df.columns.str.endswith(\"_RELOC\") | df.columns.str.endswith(\"_SEL\")]\n",
    "#     df[xpath_sel_columns] = df[xpath_sel_columns].applymap(replace_greater_than_one)\n",
    "\n",
    "    max_dos=-1\n",
    "    column_to_add=None\n",
    "    sel_columns=[]\n",
    "    for col in df.columns:\n",
    "        if col.endswith(\"_SEL\"):\n",
    "            dos= calculate_duration_of_survival(col)\n",
    "            if dos>max_dos:\n",
    "                max_dos=dos\n",
    "                column_to_add=col\n",
    "            if col.startswith(\"xpath\"):\n",
    "                sel_columns.append(column_to_add)\n",
    "                max_dos=-1\n",
    "                column_to_add=None\n",
    "    sel_columns=pd.Index(sel_columns)\n",
    "    \n",
    "    # Iterate over all rows in the DataFrame using iterrows()\n",
    "    total_acc_RELOC = 0\n",
    "    total_acc_SEL = 0\n",
    "    num_rows = len(df)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        total_acc_RELOC += compute_reloc_recoil(row)\n",
    "        total_acc_SEL += compute_sel_recoil(row)\n",
    "    average_acc_RELOC = total_acc_RELOC / num_rows\n",
    "    average_acc_SEL = total_acc_SEL / num_rows\n",
    "    \n",
    "#     accuracy = df[all_columns].apply(calculate_accuracy)\n",
    "#     accuracy = df[xpath_sel_columns].apply(calculate_accuracy)\n",
    "\n",
    "    duration_of_survival = df[all_columns].apply(calculate_duration_of_survival)\n",
    "    total_dos=0\n",
    "    for index, dos in enumerate(duration_of_survival[sel_columns].values):\n",
    "        total_dos=total_dos+dos\n",
    "    total_dos= total_dos/len(duration_of_survival)\n",
    "    dos_sel.append(total_dos)\n",
    "    \n",
    "    total_dos=0\n",
    "    for index, dos in enumerate(duration_of_survival[reloc_columns].values):\n",
    "        total_dos=total_dos+dos\n",
    "    total_dos= total_dos/len(duration_of_survival)\n",
    "    dos_RELOC.append(total_dos)\n",
    "#     duration_of_survival = df[xpath_sel_columns].apply(calculate_duration_of_survival)\n",
    "    \n",
    "    locator_length = df[all_columns].apply(calculate_locator_length)\n",
    "#     correlation_accuracy = accuracy.corr(duration_of_survival)\n",
    "#     correlation_accuracy = accuracy.corr(locator_length)\n",
    "    correlation_length = locator_length.corr(duration_of_survival)\n",
    "#     print(\"Accuracy :\"+str(correlation_accuracy))\n",
    "#     print(\"Length :\"+str(correlation_length))\n",
    "    if average_acc_RELOC>1:\n",
    "        print(file)\n",
    "        df_d = df\n",
    "    accuracies_RELOC.append(average_acc_RELOC)\n",
    "    accuracies_SEL.append(average_acc_SEL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb71c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon statistic RELOC: 618.0\n",
      "p-value RELOC: 1.2918945362457503e-14\n",
      "Reject the null hypothesis: The distributions are different.\n",
      "\n",
      "Wilcoxon statistic SEL: 534.0\n",
      "p-value SEL: 1.3138032799678164e-15\n",
      "Reject the null hypothesis: The distributions are different.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "\n",
    "alpha = 0.05\n",
    "# Perform the Wilcoxon signed-rank test\n",
    "statistic, p_value = stats.wilcoxon(dos_RELOC, accuracies_RELOC)\n",
    "\n",
    "print(\"Wilcoxon statistic RELOC:\", statistic)\n",
    "print(\"p-value RELOC:\", p_value)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The distributions are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The distributions are similar.\")\n",
    "print()\n",
    "statistic, p_value = stats.wilcoxon(dos_sel, accuracies_SEL)\n",
    "\n",
    "print(\"Wilcoxon statistic SEL:\", statistic)\n",
    "print(\"p-value SEL:\", p_value)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The distributions are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The distributions are similar.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
