{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          position  changed\n",
      "position   1.00000 -0.02941\n",
      "changed   -0.02941  1.00000\n",
      "\n",
      "            depth   changed\n",
      "depth    1.000000  0.071256\n",
      "changed  0.071256  1.000000\n",
      "\n",
      "             nr_siblings   changed\n",
      "nr_siblings     1.000000 -0.035157\n",
      "changed        -0.035157  1.000000\n",
      "\n",
      "             nr_children   changed\n",
      "nr_children     1.000000 -0.036122\n",
      "changed        -0.036122  1.000000\n",
      "\n",
      "          lxpath  changed\n",
      "lxpath   1.00000  0.06755\n",
      "changed  0.06755  1.00000\n",
      "\n",
      "\n",
      "position\n",
      "SpearmanrResult(correlation=-0.029410063191568844, pvalue=2.3000111685560715e-73)\n",
      "depth\n",
      "SpearmanrResult(correlation=0.07125577114381565, pvalue=0.0)\n",
      "nr_siblings\n",
      "SpearmanrResult(correlation=-0.0351573988458202, pvalue=4.830554136126205e-104)\n",
      "nr_children\n",
      "SpearmanrResult(correlation=-0.036121728857713295, pvalue=1.0067965595987004e-109)\n",
      "lxpath\n",
      "SpearmanrResult(correlation=0.06754966070500934, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "df_1688 = pd.read_csv(\"/Volumes/JJ_Media/Data/RobustPrediction/wo_noise/feature_list_1688.tsv\", delimiter=\"\\t\")\n",
    "df_1688['lxpath'] = df_1688.xpath.apply(lambda v:len(v.split(\"/\")))\n",
    "df_1688.changed = df_1688.changed.apply(lambda v:int(v))\n",
    "df_1688.siblings = df_1688.siblings.apply(lambda v:eval(v))\n",
    "# correlation \n",
    "features = ['position', 'depth', 'nr_siblings', 'nr_children', 'lxpath']\n",
    "for ftype in features:\n",
    "    print (df_1688[[ftype, 'changed']].corr(method = 'spearman'))\n",
    "    print ()\n",
    "print ()\n",
    "for ftype in features:\n",
    "    print (ftype)\n",
    "    print (spearmanr(df_1688[ftype].values, df_1688.changed.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          position   changed\n",
      "position  1.000000 -0.169566\n",
      "changed  -0.169566  1.000000\n",
      "\n",
      "            depth   changed\n",
      "depth    1.000000  0.229913\n",
      "changed  0.229913  1.000000\n",
      "\n",
      "             nr_siblings   changed\n",
      "nr_siblings     1.000000 -0.087361\n",
      "changed        -0.087361  1.000000\n",
      "\n",
      "             nr_children   changed\n",
      "nr_children     1.000000 -0.132111\n",
      "changed        -0.132111  1.000000\n",
      "\n",
      "           lxpath   changed\n",
      "lxpath   1.000000  0.208595\n",
      "changed  0.208595  1.000000\n",
      "\n",
      "\n",
      "position\n",
      "SpearmanrResult(correlation=-0.16956587398648945, pvalue=0.0)\n",
      "depth\n",
      "SpearmanrResult(correlation=0.2299133514118026, pvalue=0.0)\n",
      "nr_siblings\n",
      "SpearmanrResult(correlation=-0.0873611231845423, pvalue=0.0)\n",
      "nr_children\n",
      "SpearmanrResult(correlation=-0.13211054221728108, pvalue=0.0)\n",
      "lxpath\n",
      "SpearmanrResult(correlation=0.20859463006879164, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "df_104 = pd.read_csv(\"/Volumes/JJ_Media/Data/RobustPrediction/wo_noise/feature_list_104.tsv\", delimiter=\"\\t\")\n",
    "df_104['lxpath'] = df_104.xpath.apply(lambda v:len(v.split(\"/\")))\n",
    "df_104.changed = df_104.changed.apply(lambda v:int(v))\n",
    "df_104.siblings = df_104.siblings.apply(lambda v:eval(v))\n",
    "# correlation \n",
    "features = ['position', 'depth', 'nr_siblings', 'nr_children', 'lxpath']\n",
    "for ftype in features:\n",
    "    print (df_104[[ftype, 'changed']].corr(method = 'spearman'))\n",
    "    print ()\n",
    "print ()\n",
    "for ftype in features:\n",
    "    print (ftype)\n",
    "    print (spearmanr(df_104[ftype].values, df_104.changed.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the results of 104 vs 1688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position\n",
      "SpearmanrResult(correlation=-0.16956587398648945, pvalue=0.0)\n",
      "depth\n",
      "SpearmanrResult(correlation=0.2299133514118026, pvalue=0.0)\n",
      "nr_siblings\n",
      "SpearmanrResult(correlation=-0.0873611231845423, pvalue=0.0)\n",
      "nr_children\n",
      "SpearmanrResult(correlation=-0.13211054221728108, pvalue=0.0)\n",
      "lxpath\n",
      "SpearmanrResult(correlation=0.20859463006879164, pvalue=0.0)\n",
      "\n",
      "=====\n",
      "\n",
      "position\n",
      "SpearmanrResult(correlation=-0.029410063191568844, pvalue=2.3000111685560715e-73)\n",
      "depth\n",
      "SpearmanrResult(correlation=0.07125577114381565, pvalue=0.0)\n",
      "nr_siblings\n",
      "SpearmanrResult(correlation=-0.0351573988458202, pvalue=4.830554136126205e-104)\n",
      "nr_children\n",
      "SpearmanrResult(correlation=-0.036121728857713295, pvalue=1.0067965595987004e-109)\n",
      "lxpath\n",
      "SpearmanrResult(correlation=0.06754966070500934, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "for ftype in features:\n",
    "    print (ftype)\n",
    "    print (spearmanr(df_104[ftype].values, df_104.changed.values))\n",
    "\n",
    "print (\"\\n=====\\n\")\n",
    "for ftype in features:\n",
    "    print (ftype)\n",
    "    print (spearmanr(df_1688[ftype].values, df_1688.changed.values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems that currently, for 104, we have some potentials in terms of position (not sure), (nr_sibling, may too wek), depth, nr_children, and lxpath.\n",
    "\n",
    "Actually, for 1688, the trend itself is the same: depth > lxpath > nr_children > (this signal becomes weaker) nr_sibilings > position (actully, this revesed with nr_siblings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98,) 443920\n",
      "(98,) 379351\n"
     ]
    }
   ],
   "source": [
    "print(df_104.timestamp.unique().shape, len(df_104))\n",
    "print(df_1688.timestamp.unique().shape, len(df_1688))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443920 16670 3.755181113714183\n",
      "379351 13058 3.442194695677618\n"
     ]
    }
   ],
   "source": [
    "# the number of changed\n",
    "print (len(df_104), df_104.changed.sum(), 100*df_104.changed.sum()/len(df_104))\n",
    "print (len(df_1688), df_1688.changed.sum(), 100*df_1688.changed.sum()/len(df_1688))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, it is not about the ratio of changed ones that affect the results .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(data, feature_names, oversamp = True):   \n",
    "    X = data[feature_names].values\n",
    "    y = data.changed.values\n",
    "\n",
    "    if oversamp:\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        sm = SMOTE(random_state=0)\n",
    "        X_res, y_res = sm.fit_resample(X, y)\n",
    "    else:\n",
    "        from imblearn.under_sampling import RandomUnderSampler \n",
    "        centroid = RandomUnderSampler(random_state = 0)\n",
    "        X_res, y_res = centroid.fit_resample(X, y)\n",
    "    \n",
    "    return X_res, y_res \n",
    "\n",
    "def resample_vectors(X, y, oversamp = True):   \n",
    "    if oversamp:\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        sm = SMOTE(random_state=0)\n",
    "        X_res, y_res = sm.fit_resample(X, y)\n",
    "    else:\n",
    "        from imblearn.under_sampling import RandomUnderSampler \n",
    "        centroid = RandomUnderSampler(random_state = 0)\n",
    "        X_res, y_res = centroid.fit_resample(X, y)\n",
    "    \n",
    "    return X_res, y_res \n",
    "\n",
    "def compute_corr(X, y, ftypes):\n",
    "    for idx, ftype in enumerate(ftypes):\n",
    "        print (ftype)\n",
    "        print (\"\\t\", spearmanr(X[:,idx], y))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Oversampling ===\n",
      "position\n",
      "\t SpearmanrResult(correlation=-0.5451968732354452, pvalue=0.0)\n",
      "depth\n",
      "\t SpearmanrResult(correlation=0.6270237843895687, pvalue=0.0)\n",
      "nr_siblings\n",
      "\t SpearmanrResult(correlation=-0.23025238796447, pvalue=0.0)\n",
      "nr_children\n",
      "\t SpearmanrResult(correlation=-0.44329421304211303, pvalue=0.0)\n",
      "lxpath\n",
      "\t SpearmanrResult(correlation=0.5770531360381647, pvalue=0.0)\n",
      "=== Undersampling ===\n",
      "position\n",
      "\t SpearmanrResult(correlation=-0.5425495894402638, pvalue=0.0)\n",
      "depth\n",
      "\t SpearmanrResult(correlation=0.6254013532252595, pvalue=0.0)\n",
      "nr_siblings\n",
      "\t SpearmanrResult(correlation=-0.2291494219058163, pvalue=0.0)\n",
      "nr_children\n",
      "\t SpearmanrResult(correlation=-0.44227273757814173, pvalue=0.0)\n",
      "lxpath\n",
      "\t SpearmanrResult(correlation=0.5766459404080755, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "oversamp = True\n",
    "print (\"=== Oversampling ===\")\n",
    "over_X_104_res, over_y_104_res  = resample(df_104, features, oversamp = oversamp)\n",
    "compute_corr(over_X_104_res, over_y_104_res, features)\n",
    "\n",
    "oversamp = False\n",
    "print (\"=== Undersampling ===\")\n",
    "under_X_104_res, under_y_104_res  = resample(df_104, features, oversamp = oversamp)\n",
    "compute_corr(under_X_104_res, under_y_104_res, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Oversampling ===\n",
      "position\n",
      "\t SpearmanrResult(correlation=-0.08608750513789196, pvalue=0.0)\n",
      "depth\n",
      "\t SpearmanrResult(correlation=0.19603700740261298, pvalue=0.0)\n",
      "nr_siblings\n",
      "\t SpearmanrResult(correlation=-0.09647232025702354, pvalue=0.0)\n",
      "nr_children\n",
      "\t SpearmanrResult(correlation=-0.10668040995042985, pvalue=0.0)\n",
      "lxpath\n",
      "\t SpearmanrResult(correlation=0.1854184563693287, pvalue=0.0)\n",
      "=== Undersampling ===\n",
      "position\n",
      "\t SpearmanrResult(correlation=-0.08230722206139451, pvalue=1.6970689739336358e-40)\n",
      "depth\n",
      "\t SpearmanrResult(correlation=0.18908196267141328, pvalue=9.309685167692483e-209)\n",
      "nr_siblings\n",
      "\t SpearmanrResult(correlation=-0.09481733336529916, pvalue=3.190472921859148e-53)\n",
      "nr_children\n",
      "\t SpearmanrResult(correlation=-0.10540193060491397, pvalue=2.084051061384027e-65)\n",
      "lxpath\n",
      "\t SpearmanrResult(correlation=0.17892078277553766, pvalue=8.725556961382762e-187)\n"
     ]
    }
   ],
   "source": [
    "oversamp = True\n",
    "print (\"=== Oversampling ===\")\n",
    "over_X_1688_res, over_y_1688_res  = resample(df_1688, features, oversamp = oversamp)\n",
    "compute_corr(over_X_1688_res, over_y_1688_res, features)\n",
    "\n",
    "oversamp = False\n",
    "print (\"=== Undersampling ===\")\n",
    "under_X_1688_res, under_y_1688_res  = resample(df_1688, features, oversamp = oversamp)\n",
    "compute_corr(under_X_1688_res, under_y_1688_res, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much, but it seems like the signals increase slightly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33340,), (854500,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_X_1688_res.shape, under_X_104_res.shape\n",
    "under_y_104_res.shape, over_y_104_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "data = df_104 \n",
    "X = data[features].values\n",
    "y = data.changed.values \n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.33, random_state=0)\n",
    "# resample \n",
    "## undersample\n",
    "res_train_X, res_train_y  = resample_vectors(train_X, train_y, oversamp=False) \n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(res_train_X, res_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9133840842701603\n",
      "0.8543558097942577\n"
     ]
    }
   ],
   "source": [
    "#clf.score(train_X, train_y)\n",
    "train_predc_prob = clf.predict_proba(res_train_X)\n",
    "test_predc_prob = clf.predict_proba(test_X)\n",
    "train_predc = np.argmax(train_predc_prob, axis = 1)\n",
    "test_predc = np.argmax(test_predc_prob, axis = 1)\n",
    "\n",
    "print (np.sum(train_predc == res_train_y)/len(res_train_y))\n",
    "print (np.sum(test_predc == test_y)/len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.9133840842701602\n",
      "test 0.9140215780892538\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "print('train', balanced_accuracy_score(res_train_y, train_predc))\n",
    "print('test', balanced_accuracy_score(test_y, test_predc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6696590909090909\n",
      "0.6204847187385171\n",
      "train 0.6696590909090909\n",
      "test 0.644952934662409\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "data = df_1688\n",
    "X = data[features].values\n",
    "y = data.changed.values \n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.33, random_state=0)\n",
    "# resample \n",
    "## undersample\n",
    "res_train_X, res_train_y  = resample_vectors(train_X, train_y, oversamp=False) \n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(res_train_X, res_train_y)\n",
    "\n",
    "#clf.score(train_X, train_y)\n",
    "train_predc_prob = clf.predict_proba(res_train_X)\n",
    "test_predc_prob = clf.predict_proba(test_X)\n",
    "train_predc = np.argmax(train_predc_prob, axis = 1)\n",
    "test_predc = np.argmax(test_predc_prob, axis = 1)\n",
    "\n",
    "print (np.sum(train_predc == res_train_y)/len(res_train_y))\n",
    "print (np.sum(test_predc == test_y)/len(test_y))\n",
    "\n",
    "print('train', balanced_accuracy_score(res_train_y, train_predc))\n",
    "print('test', balanced_accuracy_score(test_y, test_predc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
