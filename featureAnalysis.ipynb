{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          position  changed\n",
      "position   1.00000 -0.02941\n",
      "changed   -0.02941  1.00000\n",
      "\n",
      "            depth   changed\n",
      "depth    1.000000  0.071256\n",
      "changed  0.071256  1.000000\n",
      "\n",
      "             nr_siblings   changed\n",
      "nr_siblings     1.000000 -0.035157\n",
      "changed        -0.035157  1.000000\n",
      "\n",
      "             nr_children   changed\n",
      "nr_children     1.000000 -0.036122\n",
      "changed        -0.036122  1.000000\n",
      "\n",
      "          lxpath  changed\n",
      "lxpath   1.00000  0.06755\n",
      "changed  0.06755  1.00000\n",
      "\n",
      "\n",
      "position\n",
      "SpearmanrResult(correlation=-0.029410063191568844, pvalue=2.3000111685560715e-73)\n",
      "depth\n",
      "SpearmanrResult(correlation=0.07125577114381565, pvalue=0.0)\n",
      "nr_siblings\n",
      "SpearmanrResult(correlation=-0.0351573988458202, pvalue=4.830554136126205e-104)\n",
      "nr_children\n",
      "SpearmanrResult(correlation=-0.036121728857713295, pvalue=1.0067965595987004e-109)\n",
      "lxpath\n",
      "SpearmanrResult(correlation=0.06754966070500934, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "df_1688 = pd.read_csv(\"/Volumes/JJ_Media/Data/RobustPrediction/wo_noise/feature_list_1688.tsv\", delimiter=\"\\t\")\n",
    "df_1688['lxpath'] = df_1688.xpath.apply(lambda v:len(v.split(\"/\")))\n",
    "df_1688.changed = df_1688.changed.apply(lambda v:int(v))\n",
    "df_1688.siblings = df_1688.siblings.apply(lambda v:eval(v))\n",
    "# correlation \n",
    "features = ['position', 'depth', 'nr_siblings', 'nr_children', 'lxpath']\n",
    "for ftype in features:\n",
    "    print (df_1688[[ftype, 'changed']].corr(method = 'spearman'))\n",
    "    print ()\n",
    "print ()\n",
    "for ftype in features:\n",
    "    print (ftype)\n",
    "    print (spearmanr(df_1688[ftype].values, df_1688.changed.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1688.timestamp.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xj/6_33yk_n1p1_zlttg7scvdlxp4s8cg/T/ipykernel_89863/637007519.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_104\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lxpath'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_104\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_104\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchanged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_104\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchanged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_104\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msiblings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_104\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msiblings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# correlation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'position'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'depth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nr_siblings'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nr_children'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxpath'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/var/folders/xj/6_33yk_n1p1_zlttg7scvdlxp4s8cg/T/ipykernel_89863/637007519.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_104\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lxpath'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_104\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_104\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchanged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_104\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchanged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_104\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msiblings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_104\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msiblings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# correlation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'position'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'depth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nr_siblings'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nr_children'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxpath'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "df_104 = pd.read_csv(\"/Volumes/JJ_Media/Data/RobustPrediction/wo_noise/feature_list_104.tsv\", delimiter=\"\\t\")\n",
    "df_104['lxpath'] = df_104.xpath.apply(lambda v:len(v.split(\"/\")))\n",
    "df_104.changed = df_104.changed.apply(lambda v:int(v))\n",
    "df_104.siblings = df_104.siblings.apply(lambda v:eval(v))\n",
    "# correlation \n",
    "features = ['position', 'depth', 'nr_siblings', 'nr_children', 'lxpath']\n",
    "for ftype in features:\n",
    "    print (df_104[[ftype, 'changed']].corr(method = 'spearman'))\n",
    "    print ()\n",
    "print ()\n",
    "for ftype in features:\n",
    "    print (ftype)\n",
    "    print (spearmanr(df_104[ftype].values, df_104.changed.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the results of 104 vs 1688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position\n",
      "SpearmanrResult(correlation=-0.16956587398648945, pvalue=0.0)\n",
      "depth\n",
      "SpearmanrResult(correlation=0.2299133514118026, pvalue=0.0)\n",
      "nr_siblings\n",
      "SpearmanrResult(correlation=-0.0873611231845423, pvalue=0.0)\n",
      "nr_children\n",
      "SpearmanrResult(correlation=-0.13211054221728108, pvalue=0.0)\n",
      "lxpath\n",
      "SpearmanrResult(correlation=0.20859463006879164, pvalue=0.0)\n",
      "\n",
      "=====\n",
      "\n",
      "position\n",
      "SpearmanrResult(correlation=-0.029410063191568844, pvalue=2.3000111685560715e-73)\n",
      "depth\n",
      "SpearmanrResult(correlation=0.07125577114381565, pvalue=0.0)\n",
      "nr_siblings\n",
      "SpearmanrResult(correlation=-0.0351573988458202, pvalue=4.830554136126205e-104)\n",
      "nr_children\n",
      "SpearmanrResult(correlation=-0.036121728857713295, pvalue=1.0067965595987004e-109)\n",
      "lxpath\n",
      "SpearmanrResult(correlation=0.06754966070500934, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "for ftype in features:\n",
    "    print (ftype)\n",
    "    print (spearmanr(df_104[ftype].values, df_104.changed.values))\n",
    "\n",
    "print (\"\\n=====\\n\")\n",
    "for ftype in features:\n",
    "    print (ftype)\n",
    "    print (spearmanr(df_1688[ftype].values, df_1688.changed.values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems that currently, for 104, we have some potentials in terms of position (not sure), (nr_sibling, may too wek), depth, nr_children, and lxpath.\n",
    "\n",
    "Actually, for 1688, the trend itself is the same: depth > lxpath > nr_children > (this signal becomes weaker) nr_sibilings > position (actully, this revesed with nr_siblings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98,) 443920\n",
      "(98,) 379351\n"
     ]
    }
   ],
   "source": [
    "print(df_104.timestamp.unique().shape, len(df_104))\n",
    "print(df_1688.timestamp.unique().shape, len(df_1688))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443920 16670 3.755181113714183\n",
      "379351 13058 3.442194695677618\n"
     ]
    }
   ],
   "source": [
    "# the number of changed\n",
    "print (len(df_104), df_104.changed.sum(), 100*df_104.changed.sum()/len(df_104))\n",
    "print (len(df_1688), df_1688.changed.sum(), 100*df_1688.changed.sum()/len(df_1688))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, it is not about the ratio of changed ones that affect the results .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(data, feature_names, oversamp = True):   \n",
    "    X = data[feature_names].values\n",
    "    y = data.changed.values\n",
    "\n",
    "    if oversamp:\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        sm = SMOTE(random_state=0)\n",
    "        X_res, y_res = sm.fit_resample(X, y)\n",
    "    else:\n",
    "        from imblearn.under_sampling import RandomUnderSampler \n",
    "        centroid = RandomUnderSampler(random_state = 0)\n",
    "        X_res, y_res = centroid.fit_resample(X, y)\n",
    "    \n",
    "    return X_res, y_res \n",
    "\n",
    "def resample_vectors(X, y, oversamp = True):   \n",
    "    if oversamp:\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        sm = SMOTE(random_state=0)\n",
    "        X_res, y_res = sm.fit_resample(X, y)\n",
    "    else:\n",
    "        from imblearn.under_sampling import RandomUnderSampler \n",
    "        centroid = RandomUnderSampler(random_state = 0)\n",
    "        X_res, y_res = centroid.fit_resample(X, y)\n",
    "    \n",
    "    return X_res, y_res \n",
    "\n",
    "def compute_corr(X, y, ftypes):\n",
    "    for idx, ftype in enumerate(ftypes):\n",
    "        print (ftype)\n",
    "        print (\"\\t\", spearmanr(X[:,idx], y))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Oversampling ===\n",
      "position\n",
      "\t SpearmanrResult(correlation=-0.5451968732354452, pvalue=0.0)\n",
      "depth\n",
      "\t SpearmanrResult(correlation=0.6270237843895687, pvalue=0.0)\n",
      "nr_siblings\n",
      "\t SpearmanrResult(correlation=-0.23025238796447, pvalue=0.0)\n",
      "nr_children\n",
      "\t SpearmanrResult(correlation=-0.44329421304211303, pvalue=0.0)\n",
      "lxpath\n",
      "\t SpearmanrResult(correlation=0.5770531360381647, pvalue=0.0)\n",
      "=== Undersampling ===\n",
      "position\n",
      "\t SpearmanrResult(correlation=-0.5425495894402638, pvalue=0.0)\n",
      "depth\n",
      "\t SpearmanrResult(correlation=0.6254013532252595, pvalue=0.0)\n",
      "nr_siblings\n",
      "\t SpearmanrResult(correlation=-0.2291494219058163, pvalue=0.0)\n",
      "nr_children\n",
      "\t SpearmanrResult(correlation=-0.44227273757814173, pvalue=0.0)\n",
      "lxpath\n",
      "\t SpearmanrResult(correlation=0.5766459404080755, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "oversamp = True\n",
    "print (\"=== Oversampling ===\")\n",
    "over_X_104_res, over_y_104_res  = resample(df_104, features, oversamp = oversamp)\n",
    "compute_corr(over_X_104_res, over_y_104_res, features)\n",
    "\n",
    "oversamp = False\n",
    "print (\"=== Undersampling ===\")\n",
    "under_X_104_res, under_y_104_res  = resample(df_104, features, oversamp = oversamp)\n",
    "compute_corr(under_X_104_res, under_y_104_res, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Oversampling ===\n",
      "position\n",
      "\t SpearmanrResult(correlation=-0.08608750513789196, pvalue=0.0)\n",
      "depth\n",
      "\t SpearmanrResult(correlation=0.19603700740261298, pvalue=0.0)\n",
      "nr_siblings\n",
      "\t SpearmanrResult(correlation=-0.09647232025702354, pvalue=0.0)\n",
      "nr_children\n",
      "\t SpearmanrResult(correlation=-0.10668040995042985, pvalue=0.0)\n",
      "lxpath\n",
      "\t SpearmanrResult(correlation=0.1854184563693287, pvalue=0.0)\n",
      "=== Undersampling ===\n",
      "position\n",
      "\t SpearmanrResult(correlation=-0.08230722206139451, pvalue=1.6970689739336358e-40)\n",
      "depth\n",
      "\t SpearmanrResult(correlation=0.18908196267141328, pvalue=9.309685167692483e-209)\n",
      "nr_siblings\n",
      "\t SpearmanrResult(correlation=-0.09481733336529916, pvalue=3.190472921859148e-53)\n",
      "nr_children\n",
      "\t SpearmanrResult(correlation=-0.10540193060491397, pvalue=2.084051061384027e-65)\n",
      "lxpath\n",
      "\t SpearmanrResult(correlation=0.17892078277553766, pvalue=8.725556961382762e-187)\n"
     ]
    }
   ],
   "source": [
    "oversamp = True\n",
    "print (\"=== Oversampling ===\")\n",
    "over_X_1688_res, over_y_1688_res  = resample(df_1688, features, oversamp = oversamp)\n",
    "compute_corr(over_X_1688_res, over_y_1688_res, features)\n",
    "\n",
    "oversamp = False\n",
    "print (\"=== Undersampling ===\")\n",
    "under_X_1688_res, under_y_1688_res  = resample(df_1688, features, oversamp = oversamp)\n",
    "compute_corr(under_X_1688_res, under_y_1688_res, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much, but it seems like the signals increase slightly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33340,), (854500,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_X_1688_res.shape, under_X_104_res.shape\n",
    "under_y_104_res.shape, over_y_104_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "data = df_104 \n",
    "X = data[features].values\n",
    "y = data.changed.values \n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.33, random_state=0)\n",
    "# resample \n",
    "## undersample\n",
    "res_train_X, res_train_y  = resample_vectors(train_X, train_y, oversamp=False) \n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(res_train_X, res_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9133840842701603\n",
      "0.8543421573579806\n"
     ]
    }
   ],
   "source": [
    "#clf.score(train_X, train_y)\n",
    "train_predc_prob = clf.predict_proba(res_train_X)\n",
    "test_predc_prob = clf.predict_proba(test_X)\n",
    "train_predc = np.argmax(train_predc_prob, axis = 1)\n",
    "test_predc = np.argmax(test_predc_prob, axis = 1)\n",
    "\n",
    "print (np.sum(train_predc == res_train_y)/len(res_train_y))\n",
    "print (np.sum(test_predc == test_y)/len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.9133840842701602\n",
      "test 0.9140144919716668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "print('train', balanced_accuracy_score(res_train_y, train_predc))\n",
    "print('test', balanced_accuracy_score(test_y, test_predc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6696590909090909\n",
      "0.6159394820507086\n",
      "train 0.6696590909090909\n",
      "test 0.6442996650235517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "data = df_1688\n",
    "X = data[features].values\n",
    "y = data.changed.values \n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.33, random_state=0)\n",
    "# resample \n",
    "## undersample\n",
    "res_train_X, res_train_y  = resample_vectors(train_X, train_y, oversamp=False) \n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(res_train_X, res_train_y)\n",
    "\n",
    "#clf.score(train_X, train_y)\n",
    "train_predc_prob = clf.predict_proba(res_train_X)\n",
    "test_predc_prob = clf.predict_proba(test_X)\n",
    "train_predc = np.argmax(train_predc_prob, axis = 1)\n",
    "test_predc = np.argmax(test_predc_prob, axis = 1)\n",
    "\n",
    "print (np.sum(train_predc == res_train_y)/len(res_train_y))\n",
    "print (np.sum(test_predc == test_y)/len(test_y))\n",
    "\n",
    "print('train', balanced_accuracy_score(res_train_y, train_predc))\n",
    "print('test', balanced_accuracy_score(test_y, test_predc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time sequence\n",
    "\n",
    "currently, don't care about the timestamp granularity during the training (collect all & train) (meaning, currenlty the batch (if we use DNN terms) is the entire training dataset)\n",
    "\n",
    "For prediction, can do whatever you want: either as the entire dataset or per timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['node', 'timestamp', 'position', 'depth', 'nr_siblings', 'nr_children',\n",
      "       'xpath', 'siblings', 'changed', 'lxpath'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df_104\n",
    "print(df_104.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98,)\n"
     ]
    }
   ],
   "source": [
    "# get unique timestamps\n",
    "uniq_timestamps = df.timestamp.unique()\n",
    "print (uniq_timestamps.shape)\n",
    "uniq_timestamps.sort() # from the oldest to the latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68,) (30,)\n"
     ]
    }
   ],
   "source": [
    "# divide the collected timstamps to train (older) and test (more recents)\n",
    "indices = np.arange(len(uniq_timestamps))\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.3)\n",
    "print (train_indices.shape, test_indices.shape)\n",
    "ts_for_train = uniq_timestamps[train_indices]\n",
    "ts_for_test = uniq_timestamps[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9134648817802503\n",
      "0.8586875658316331\n",
      "train 0.9134648817802503\n",
      "test 0.8854613640018452\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby('timestamp') # grouping\n",
    "# set train and test data\n",
    "train_X, train_y = None,None \n",
    "for i, t in enumerate(ts_for_train):\n",
    "    adf = grouped.get_group(t)\n",
    "    if i == 0:\n",
    "        train_X = adf[features].values\n",
    "        train_y = adf.changed.values\n",
    "    else:\n",
    "        train_X = np.append(train_X, adf[features].values, axis = 0)\n",
    "        train_y = np.append(train_y, adf.changed.values)\n",
    "\n",
    "test_X, test_y = None,None \n",
    "for i, t in enumerate(ts_for_test):\n",
    "    adf = grouped.get_group(t)\n",
    "    if i == 0:\n",
    "        test_X = adf[features].values\n",
    "        test_y = adf.changed.values\n",
    "    else:\n",
    "        test_X = np.append(test_X, adf[features].values, axis = 0)\n",
    "        test_y = np.append(test_y, adf.changed.values)\n",
    "\n",
    "# resample (the same as before)\n",
    "## undersample\n",
    "res_train_X, res_train_y  = resample_vectors(train_X, train_y, oversamp=False) \n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(res_train_X, res_train_y)\n",
    "\n",
    "#clf.score(train_X, train_y)\n",
    "train_predc_prob = clf.predict_proba(res_train_X)\n",
    "test_predc_prob = clf.predict_proba(test_X)\n",
    "train_predc = np.argmax(train_predc_prob, axis = 1)\n",
    "test_predc = np.argmax(test_predc_prob, axis = 1)\n",
    "\n",
    "print ('train acc', np.sum(train_predc == res_train_y)/len(res_train_y))\n",
    "print ('test acc', np.sum(test_predc == test_y)/len(test_y))\n",
    "\n",
    "print('train balacc', balanced_accuracy_score(res_train_y, train_predc))\n",
    "print('test balacc', balanced_accuracy_score(test_y, test_predc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 20180203045438,         \n",
      "\tacc: 0.8593333333333333        \n",
      "\tbalacc:0.9240782878248253\n",
      "For 20180411221320,         \n",
      "\tacc: 0.857550482879719        \n",
      "\tbalacc:0.9231877679756213\n",
      "For 20180223191215,         \n",
      "\tacc: 0.8575530035335689        \n",
      "\tbalacc:0.9231717193531841\n",
      "For 20180120144503,         \n",
      "\tacc: 0.8610184567489437        \n",
      "\tbalacc:0.9249491616894732\n",
      "For 20180305082408,         \n",
      "\tacc: 0.8570797437596642        \n",
      "\tbalacc:0.9201332336528449\n",
      "For 20180326191449,         \n",
      "\tacc: 0.8570797437596642        \n",
      "\tbalacc:0.9201332336528449\n",
      "For 20180303063840,         \n",
      "\tacc: 0.8570797437596642        \n",
      "\tbalacc:0.9229252453793084\n",
      "For 20180227220815,         \n",
      "\tacc: 0.8199690744422354        \n",
      "\tbalacc:0.8199690744422354\n",
      "For 20180429194224,         \n",
      "\tacc: 0.8577699736611062        \n",
      "\tbalacc:0.9178471357409713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeongju.sohn/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:2006: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 20180313004000,         \n",
      "\tacc: 0.8573006406008394        \n",
      "\tbalacc:0.9202646692563612\n",
      "For 20180413235719,         \n",
      "\tacc: 0.857550482879719        \n",
      "\tbalacc:0.9231877679756213\n",
      "For 20180214002214,         \n",
      "\tacc: 0.85726891683212        \n",
      "\tbalacc:0.9202351178255468\n",
      "For 20180321110434,         \n",
      "\tacc: 0.8570797437596642        \n",
      "\tbalacc:0.9229252453793084\n",
      "For 20180328224122,         \n",
      "\tacc: 0.8570797437596642        \n",
      "\tbalacc:0.9229252453793084\n",
      "For 20180228004844,         \n",
      "\tacc: 0.8557543627126132        \n",
      "\tbalacc:0.9058778285033744\n",
      "For 20180330230209,         \n",
      "\tacc: 0.8570797437596642        \n",
      "\tbalacc:0.9229252453793084\n",
      "For 20180205071524,         \n",
      "\tacc: 0.8590455049944506        \n",
      "\tbalacc:0.9239318104461061\n",
      "For 20180206113733,         \n",
      "\tacc: 0.8590455049944506        \n",
      "\tbalacc:0.9239318104461061\n",
      "For 20180126210808,         \n",
      "\tacc: 0.8613089937666963        \n",
      "\tbalacc:0.9250970595279872\n",
      "For 20180428172319,         \n",
      "\tacc: 0.857550482879719        \n",
      "\tbalacc:0.9231877679756213\n",
      "For 20180322122921,         \n",
      "\tacc: 0.8570797437596642        \n",
      "\tbalacc:0.9229252453793084\n",
      "For 20180123184149,         \n",
      "\tacc: 0.8613089937666963        \n",
      "\tbalacc:0.9250970595279872\n",
      "For 20180219210730,         \n",
      "\tacc: 0.85726891683212        \n",
      "\tbalacc:0.9230271939167599\n",
      "For 20180416082706,         \n",
      "\tacc: 0.913081650570676        \n",
      "\tbalacc:0.5041414260228587\n",
      "For 20180425134358,         \n",
      "\tacc: 0.857550482879719        \n",
      "\tbalacc:0.9231877679756213\n",
      "For 20180209193104,         \n",
      "\tacc: 0.8590455049944506        \n",
      "\tbalacc:0.9239318104461061\n",
      "For 20180131014354,         \n",
      "\tacc: 0.8586375779162957        \n",
      "\tbalacc:0.886865454730884\n",
      "For 20180314124428,         \n",
      "\tacc: 0.8570797437596642        \n",
      "\tbalacc:0.9229252453793084\n",
      "For 20180404035909,         \n",
      "\tacc: 0.857550482879719        \n",
      "\tbalacc:0.9231877679756213\n",
      "For 20180124193640,         \n",
      "\tacc: 0.8613089937666963        \n",
      "\tbalacc:0.9250970595279872\n",
      "On average:\n",
      "\t0.8586803255981067,\n",
      "\t0.9037090152896133\n"
     ]
    }
   ],
   "source": [
    "# per timestamp prediction for test data\n",
    "\n",
    "accs, balaccs = [], []\n",
    "for i, t in enumerate(ts_for_test):\n",
    "    adf = grouped.get_group(t)\n",
    "    test_X = adf[features].values\n",
    "    test_y = adf.changed.values\n",
    "\n",
    "    test_predc_prob = clf.predict_proba(test_X)\n",
    "    test_predc = np.argmax(test_predc_prob, axis = 1)\n",
    "\n",
    "    acc = np.sum(test_predc == test_y)/len(test_y)\n",
    "    balacc = balanced_accuracy_score(test_y, test_predc) # can raise a warning when nothing has been changed in the curent timestamp\n",
    "    print (f\"For {t}, \\\n",
    "        \\n\\tacc: {acc}\\\n",
    "        \\n\\tbalacc:{balacc}\")\n",
    "    accs.append(acc)\n",
    "    balaccs.append(balacc)\n",
    "\n",
    "print (f\"On average:\\n\\t{np.mean(accs)},\\n\\t{np.mean(balaccs)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
